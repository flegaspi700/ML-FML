{"metadata":{"kernelspec":{"name":"python391jvsc74a57bd08f0e6e8876776058453f48ad7c7dcdebdb8994a74dd96d3c38b5ba45b7b9008d","display_name":"Python 3.9.1 64-bit"},"language_info":{"name":"python","version":"3.9.1","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","\n","from warnings import filterwarnings\n","filterwarnings('ignore')"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import mean_absolute_error\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import cross_val_score\n","from statistics import mode\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.feature_selection import mutual_info_regression"],"metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Read the data\n","train_data = pd.read_csv('train.csv', index_col='Id')\n","test_data = pd.read_csv('test.csv', index_col='Id')"],"metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n","count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n","mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n","std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n","min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n","25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n","50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n","75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n","max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n","\n","         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n","count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \n","mean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \n","std      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \n","min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n","25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n","50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n","75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \n","max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n","\n","        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n","count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n","mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n","std     125.338794    66.256028      61.119149    29.317331    55.757415   \n","min       0.000000     0.000000       0.000000     0.000000     0.000000   \n","25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n","50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n","75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n","max     857.000000   547.000000     552.000000   508.000000   480.000000   \n","\n","          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n","count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n","mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n","std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n","min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n","25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n","50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n","75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n","max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n","\n","[8 rows x 37 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.000000</td>\n      <td>1201.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1452.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>...</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>56.897260</td>\n      <td>70.049958</td>\n      <td>10516.828082</td>\n      <td>6.099315</td>\n      <td>5.575342</td>\n      <td>1971.267808</td>\n      <td>1984.865753</td>\n      <td>103.685262</td>\n      <td>443.639726</td>\n      <td>46.549315</td>\n      <td>...</td>\n      <td>94.244521</td>\n      <td>46.660274</td>\n      <td>21.954110</td>\n      <td>3.409589</td>\n      <td>15.060959</td>\n      <td>2.758904</td>\n      <td>43.489041</td>\n      <td>6.321918</td>\n      <td>2007.815753</td>\n      <td>180921.195890</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>42.300571</td>\n      <td>24.284752</td>\n      <td>9981.264932</td>\n      <td>1.382997</td>\n      <td>1.112799</td>\n      <td>30.202904</td>\n      <td>20.645407</td>\n      <td>181.066207</td>\n      <td>456.098091</td>\n      <td>161.319273</td>\n      <td>...</td>\n      <td>125.338794</td>\n      <td>66.256028</td>\n      <td>61.119149</td>\n      <td>29.317331</td>\n      <td>55.757415</td>\n      <td>40.177307</td>\n      <td>496.123024</td>\n      <td>2.703626</td>\n      <td>1.328095</td>\n      <td>79442.502883</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>20.000000</td>\n      <td>21.000000</td>\n      <td>1300.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1872.000000</td>\n      <td>1950.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2006.000000</td>\n      <td>34900.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>20.000000</td>\n      <td>59.000000</td>\n      <td>7553.500000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>1954.000000</td>\n      <td>1967.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2007.000000</td>\n      <td>129975.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>50.000000</td>\n      <td>69.000000</td>\n      <td>9478.500000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>1973.000000</td>\n      <td>1994.000000</td>\n      <td>0.000000</td>\n      <td>383.500000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>2008.000000</td>\n      <td>163000.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>70.000000</td>\n      <td>80.000000</td>\n      <td>11601.500000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2000.000000</td>\n      <td>2004.000000</td>\n      <td>166.000000</td>\n      <td>712.250000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>168.000000</td>\n      <td>68.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>2009.000000</td>\n      <td>214000.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>190.000000</td>\n      <td>313.000000</td>\n      <td>215245.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>2010.000000</td>\n      <td>2010.000000</td>\n      <td>1600.000000</td>\n      <td>5644.000000</td>\n      <td>1474.000000</td>\n      <td>...</td>\n      <td>857.000000</td>\n      <td>547.000000</td>\n      <td>552.000000</td>\n      <td>508.000000</td>\n      <td>480.000000</td>\n      <td>738.000000</td>\n      <td>15500.000000</td>\n      <td>12.000000</td>\n      <td>2010.000000</td>\n      <td>755000.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 37 columns</p>\n</div>"},"metadata":{},"execution_count":6}],"source":["train_data.describe()"]},{"cell_type":"code","source":["#Data Cleaning\n","train_data.rename({'1stFlrSF': 'FirstFlrSF', '2ndFlrSF': 'SecFlrSF', '3SsnPorch': 'ThreeSsnPorch'}, axis=1, inplace=True)\n","test_data.rename({'1stFlrSF': 'FirstFlrSF', '2ndFlrSF': 'SecFlrSF', '3SsnPorch': 'ThreeSsnPorch'}, axis=1, inplace=True)\n","\n","#X_train_clean.loc[X_train_clean['MasVnrType'] == \"None\"]\n","#drop_columns = ['Alley', 'Utilities']\n","#train_data.drop(drop_columns, axis=1, inplace=True)\n","#test_data.drop(drop_columns, axis=1, inplace=True)\n","\n","\n","train_data.loc[train_data['MSZoning'] == \"C (all)\", 'MSZoning'] = \"C\"\n","test_data.loc[test_data['MSZoning'] == \"C (all)\", 'MSZoning'] = \"C\"\n","\n","train_data['SaleType'].fillna(value=\"Oth\", inplace=True)\n","test_data['SaleType'].fillna(value=\"Oth\", inplace=True)\n","\n","train_data['Functional'].fillna(value=\"Typ\", inplace=True)\n","test_data['Functional'].fillna(value=\"Typ\", inplace=True)\n","\n","\n","for column in train_data[['MSZoning', 'Electrical', 'KitchenQual', 'Utilities']]:\n","    train_data[column].fillna(train_data[column].mode()[0], inplace=True)\n","\n","for column in test_data[['MSZoning', 'Electrical', 'KitchenQual', 'Utilities']]:\n","    test_data[column].fillna(test_data[column].mode()[0], inplace=True)\n","\n","train_data['LotFrontage'].fillna(train_data['LotFrontage'].mean(), inplace=True)\n","test_data['LotFrontage'].fillna(test_data['LotFrontage'].mean(), inplace=True)\n","\n","\n","for column in train_data[['MasVnrType', 'MiscFeature', 'Alley', 'Exterior1st', 'Exterior2nd']]:\n","    train_data[column].fillna(value=\"None\", inplace=True)\n","for column in test_data[['MasVnrType', 'MiscFeature', 'Alley', 'Exterior1st', 'Exterior2nd']]:\n","    test_data[column].fillna(value=\"None\", inplace=True)\n","    \n","for column in train_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n","                          'BsmtFinType2', 'GarageType', 'GarageFinish', \n","                          'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'FireplaceQu', \n","                         ]]:\n","    train_data[column].fillna(value=\"None\", inplace=True)\n","    \n","for column in test_data[['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n","                          'BsmtFinType2', 'GarageType', 'GarageFinish', \n","                          'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'FireplaceQu', \n","                         ]]:\n","    test_data[column].fillna(value=\"None\", inplace=True)\n","    \n","for column in train_data[['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n","                          'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', \n","                          'GarageArea', 'TotalBsmtSF',\n","                         ]]:\n","    train_data[column].fillna(value=0, inplace=True)\n","    \n","for column in test_data[['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n","                          'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', \n","                          'GarageArea', 'TotalBsmtSF',\n","                         ]]:\n","    test_data[column].fillna(value=0, inplace=True)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set Matplotlib defaults\n","plt.style.use(\"seaborn-whitegrid\")\n","plt.rc(\"figure\", autolayout=True)\n","plt.rc(\n","    \"axes\",\n","    labelweight=\"bold\",\n","    labelsize=\"large\",\n","    titleweight=\"bold\",\n","    titlesize=14,\n","    titlepad=10,\n",")\n","\n","# Utility functions from Tutorial\n","def make_mi_scores(X, y):\n","    X = X.copy()\n","    for colname in X.select_dtypes([\"object\", \"category\"]):\n","        X[colname], _ = X[colname].factorize()\n","    # All discrete features should now have integer dtypes\n","    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n","    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n","    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","    mi_scores = mi_scores.sort_values(ascending=False)\n","    return mi_scores\n","\n","\n","def plot_mi_scores(scores):\n","    scores = scores.sort_values(ascending=True)\n","    width = np.arange(len(scores))\n","    ticks = list(scores.index)\n","    plt.barh(width, scores)\n","    plt.yticks(width, ticks)\n","    plt.title(\"Mutual Information Scores\")\n","    \n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_mi = train_data.copy()\n","y_mi = X_mi.pop('SalePrice')\n","\n","mi_scores = make_mi_scores(X_mi, y_mi)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Top 20 MI:\")\n","print(mi_scores.head(20))\n","print(\"\\n\")\n","print(\"Bootom 20 MI:\")\n","print(mi_scores.tail(20))  # uncomment to see bottom 20\n","\n","plt.figure(dpi=100, figsize=(8, 5))\n","plot_mi_scores(mi_scores.head(20))\n","plt.figure(dpi=100, figsize=(8, 5))\n","plot_mi_scores(mi_scores.tail(20))  # uncomment to see bottom 20"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#features = [\"YearBuilt\", \"MoSold\", \"ScreenPorch\"]\n","#sns.relplot(\n","#    x=\"value\", y=\"SalePrice\", col=\"variable\", data=df.melt(id_vars=\"SalePrice\", value_vars=features), facet_kws=dict(sharex=False),\n","#);\n","\n","#sns.catplot(x=\"BldgType\", y=\"SalePrice\", data=df, kind=\"boxen\");\n","\n","# YOUR CODE HERE: \n","#feature = \"GrLivArea\"\n","\n","#sns.lmplot(\n","#    x=feature, y=\"SalePrice\", hue=\"BldgType\", col=\"BldgType\",\n","#    data=df, scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=5,\n","#);"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Drop columns with low MI score\n","drop_columns = [#'ExterCond',\n","                #'LotConfig',\n","                #'BsmtFullBath',\n","                #'Heating',\n","                #'BsmtHalfBath',\n","                #'Functional',\n","                #'LowQualFinSF',\n","                #'RoofMatl',\n","                #'LandSlope',\n","                #'YrSold',\n","                #'BsmtFinSF2',\n","                #'MiscFeature',\n","                #'Condition2',\n","                #'ThreeSsnPorch',\n","                'Street',\n","                'Utilities',\n","                'PoolArea',\n","                'PoolQC',\n","                'MiscVal',\n","                'MoSold', \n","                'Alley']\n","train_data.drop(drop_columns, axis=1, inplace=True)\n","test_data.drop(drop_columns, axis=1, inplace=True)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove rows with missing target, separate target from predictors\n","# Drop rows with missing SalePrice from the Train dataset\n","#train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n","\n","#Separate SalesPrice from the Train dataset\n","y = train_data.SalePrice\n","train_data.drop(['SalePrice'], axis=1, inplace=True)\n","\n","# Break off validation set from training data\n","#X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n","#                                                                train_size=0.8, test_size=0.2,\n","#                                                                random_state=1)\n","\n","# \"Cardinality\" means the number of unique values in a column\n","# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n","categorical_cols = [cname for cname in train_data.columns if\n","                   #train_data[cname].nunique() < 10 and \n","                   train_data[cname].dtype == \"object\"]\n","\n","# Select numerical columns\n","numerical_cols = [cname for cname in train_data.columns if \n","                train_data[cname].dtype in ['int64', 'float64']]\n","\n","# Keep selected columns only\n","my_cols = categorical_cols + numerical_cols\n","X_train = train_data[my_cols].copy()\n","#X_valid = X_valid_full[my_cols].copy()\n","X_test = test_data[my_cols].copy()\n","#X_train_clean = train_data[my_cols].copy()\n","#X_test_clean = test_data[my_cols].copy()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_test.shape)\n","\n","# Number of missing values in each column of training data\n","missing_val_count_by_column = (X_test.isnull().sum())\n","print(missing_val_count_by_column[missing_val_count_by_column > 0])\n","\n","X_test.describe()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Shape of training data (num_rows, num_columns)\n","print(X_train.shape)\n","\n","# Number of missing values in each column of training data\n","missing_val_count_by_column = (X_train.isnull().sum())\n","print(missing_val_count_by_column[missing_val_count_by_column > 0])\n","\n","X_train.describe()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1_train_clean = pd.DataFrame()  # dataframe to hold new features\n","\n","f1_train_clean[\"LivLotRatio\"] = train_data.GrLivArea / train_data.LotArea\n","f1_train_clean[\"Spaciousness\"] = (train_data.FirstFlrSF + train_data.SecFlrSF) / train_data.TotRmsAbvGrd\n","#f1_train_clean[\"TotalOutsideSF\"] = train_data.WoodDeckSF + train_data.OpenPorchSF + train_data.EnclosedPorch + train_data.ThreeSsnPorch + train_data.ScreenPorch\n","\n","print(f1_train_clean.shape)\n","f1_train_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f1_test_clean = pd.DataFrame()  # dataframe to hold new features\n","\n","f1_test_clean[\"LivLotRatio\"] = test_data.GrLivArea / test_data.LotArea\n","f1_test_clean[\"Spaciousness\"] = (test_data.FirstFlrSF + test_data.SecFlrSF) / test_data.TotRmsAbvGrd\n","#f1_test_clean[\"TotalOutsideSF\"] = test_data.WoodDeckSF + test_data.OpenPorchSF + test_data.EnclosedPorch + test_data.ThreeSsnPorch + test_data.ScreenPorch\n","\n","print(f1_test_clean.shape)\n","f1_test_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f2_train_clean = pd.get_dummies(train_data.BldgType, prefix=\"Bldg\")\n","# Multiply\n","f2_train_clean = f2_train_clean.mul(train_data.GrLivArea, axis=0)\n","\n","print(f2_train_clean.shape)\n","f2_train_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f2_test_clean = pd.get_dummies(test_data.BldgType, prefix=\"Bldg\")\n","# Multiply\n","f2_test_clean = f2_test_clean.mul(test_data.GrLivArea, axis=0)\n","\n","print(f2_test_clean.shape)\n","f2_test_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f3_train_clean = pd.DataFrame()\n","\n","# YOUR CODE HERE\n","porch_types = [\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"ThreeSsnPorch\", \"ScreenPorch\"]\n","f3_train_clean[\"PorchTypes\"] = train_data[porch_types].gt(0.0).sum(axis=1)\n","\n","print(f3_train_clean.shape)\n","f3_train_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f3_test_clean = pd.DataFrame()\n","\n","# YOUR CODE HERE\n","porch_types = [\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"ThreeSsnPorch\", \"ScreenPorch\"]\n","f3_test_clean[\"PorchTypes\"] = test_data[porch_types].gt(0.0).sum(axis=1)\n","\n","print(f3_test_clean.shape)\n","f3_test_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f4_train_clean = pd.DataFrame()\n","\n","# YOUR CODE HERE\n","f4_train_clean[\"MedNhbdArea\"] =  (\n","    train_data.groupby(\"Neighborhood\")  \n","    [\"GrLivArea\"]                \n","    .transform(\"median\")      \n",")\n","\n","print(f4_train_clean.shape)\n","f4_train_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f4_test_clean = pd.DataFrame()\n","\n","# YOUR CODE HERE\n","f4_test_clean[\"MedNhbdArea\"] =  (\n","    test_data.groupby(\"Neighborhood\")  \n","    [\"GrLivArea\"]                \n","    .transform(\"median\")      \n",")\n","\n","print(f4_test_clean.shape)\n","f4_test_clean"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_final = train_data.join([f1_train_clean, f2_train_clean, f3_train_clean, f4_train_clean])\n","X_test_final = test_data.join([f1_test_clean, f2_test_clean, f3_test_clean, f4_test_clean])\n","#score_dataset(X_new, y)\n","\n","print(X_train_final.shape)\n","print(X_test_final.shape)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for colname in X_train_final.select_dtypes([\"category\", \"object\"]):\n","        X_train_final[colname], _ = X_train_final[colname].factorize()\n","#for colname in X_test_final.select_dtypes([\"category\", \"object\"]):\n","#        X_test_final[colname], _ = X_test_final[colname].factorize()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_1 = X_train_final.copy()\n","#X_1.drop(X_1.iloc[:, 0:72], inplace = True, axis = 1)\n","#X_1.drop(X_1.columns[0], axis = 1, inplace = True)\n","X_2 = X_test_final.copy()\n","#X_2.drop(X_2.iloc[:, 0:72], inplace = True, axis = 1)\n","#X_2.drop(X_2.columns[0], axis = 1, inplace = True)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","\n","# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='constant')\n","\n","# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","\n","# Define model\n","model = RandomForestRegressor(n_estimators=100, random_state=0)\n","\n","# Bundle preprocessing and modeling code in a pipeline\n","clf = Pipeline(steps=[('preprocessor', preprocessor),\n","                      ('model', model)\n","                     ])\n","\n","# Preprocessing of training data, fit model \n","clf.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","preds = clf.predict(X_valid)\n","\n","print('MAE:', mean_absolute_error(y_valid, preds))\n","\n","\"\"\""],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocessing for numerical data\n","numerical_transformer = SimpleImputer(strategy='median')# Your code here\n","\n","# Preprocessing for categorical data\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","]) # Your code here\n","\n","# Bundle preprocessing for numerical and categorical data\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","\n","# Define model\n","#model = RandomForestRegressor(n_estimators=52, random_state=1) # Your code here"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make sure to comment this out, before submitting \n","\"\"\"\n","import optuna\n","\n","def objective(trial):\n","       \n","    xgb_params_2 = dict(\n","        random_state=trial.suggest_int(\"random_state\", 0, 3), \n","        num_parallel_tree=trial.suggest_int(\"num_parallel_tree\", 1, 3), \n","        max_depth=trial.suggest_int(\"max_depth\", 1, 10),\n","        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n","        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n","        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n","        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n","        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n","        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n","        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n","        \n","    )\n","    xgb_2 = XGBRegressor(**xgb_params_2) #XGBRegressor\n","    \n","    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('model', xgb_2)\n","                             ])\n","    \n","    #my_pipeline.fit(X_train, y)\n","    #preds = my_pipeline.predict(X_test)\n","    #score = mean_absolute_error(y, preds) \n","    #print('MAE:', score)\n","    #return score\n","   # return score_dataset(X_train, y_train, xgb)\n","    \n","    scores = -1 * cross_val_score(my_pipeline, X_train_final, y,\n","                              cv=5,\n","                              scoring='neg_mean_absolute_error')\n","    \n","    return scores.mean()\n","\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=40)\n","#xgb_params_2 = study.best_params\n","\n","trial = study.best_trial\n","print('Accuracy: {}'.format(trial.value))\n","print(\"Best hyperparameters: {}\".format(trial.params))\n","\n","\"\"\""],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Here is the best result I got so far. \n","#Accuracy: 14830.808106806508\n","#Best hyperparameters: {'random_state': 0, 'num_parallel_tree': 3, \n","#    'max_depth': 4, 'learning_rate': 0.01032010748146519, \n","#    'n_estimators': 3218, 'min_child_weight': 8, \n","#    'colsample_bytree': 0.2417577000580567, 'subsample': 0.7512730499135545, \n","#    'reg_alpha': 0.5274436957029306, 'reg_lambda': 0.006692716729570046}\n","\n","xgb_params = dict(random_state=0,\n","    max_depth=4,           # maximum depth of each tree - try 2 to 10\n","    learning_rate=0.01032010748146519,    # effect of each tree - try 0.0001 to 0.1\n","    n_estimators=3218,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n","    min_child_weight=8,    # minimum number of houses in a leaf - try 1 to 10\n","    colsample_bytree=0.2417577000580567,  # fraction of features (columns) per tree - try 0.2 to 1.0\n","    subsample=0.7512730499135545,         # 0.7 fraction of instances (rows) per tree - try 0.2 to 1.0\n","    reg_alpha=0.5274436957029306,         # 0.5 L1 regularization (like LASSO) - try 0.0 to 10.0\n","    reg_lambda=0.006692716729570046,        # L2 regularization (like Ridge) - try 0.0 to 10.0                 \n","    num_parallel_tree=3  # set > 1 for boosted random forests\n","                         ) # Your code here\n","\n","my_model = XGBRegressor(**xgb_params)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bundle preprocessing and modeling code in a pipeline\n","my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n","                              ('model', my_model)\n","                              ])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Multiply by -1 since sklearn calculates *negative* MAE\n","log_y = np.log(y)\n","scores = -1 * cross_val_score(my_model, X_1, log_y,\n","                              cv=5,\n","                              scoring='neg_mean_absolute_error')\n","\n","print(\"MAE scores:\\n\", scores)\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Average MAE score:\", scores.mean())\n","\n","#14879.336951519692 and \n","#Average MAE score: 0.0800612423227955"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n","\n","score = np.sqrt(scores.mean())\n","print(score)\n","\n","#121.91495011716945\n","#finalMAE is ranking 13449\n","\n","#0.28295095391745106"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocessing of training data, fit model \n","#my_pipeline.fit(X_1, y)\n","my_model.fit(X_1, log_y)\n","\n","# Preprocessing of test data, fit model\n","preds_test = np.exp(my_model.predict(X_2)) # Your code here\n","\n","# Preprocessing of training data, fit model \n","#my_pipeline.fit(X_train, y_train)\n","\n","# Preprocessing of validation data, get predictions\n","#preds = my_pipeline.predict(X_valid)\n","\n","# Evaluate the model\n","#score = mean_absolute_error(y, preds_test)\n","#print('MAE:', score)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save test predictions to file\n","output = pd.DataFrame({'Id': X_2.index,\n","                       'SalePrice': preds_test})\n","output.to_csv('submission.csv', index=False)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}